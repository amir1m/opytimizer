# -*- coding: utf-8 -*-
"""Adv Training MNIST v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k2ERWBslpdc6MfISrQnKTnlIPJCb2tAN

#Install Opytimizer
"""

! pip install opytimizer

import os
os.kill(os.getpid(), 9)

"""#Install ART and Swarmpackage!"""

! pip install adversarial-robustness-toolbox

! pip install SwarmPackagePy

"""#Imports"""

SEED = 42
from __future__ import absolute_import, division, print_function, unicode_literals

from keras.models import Sequential, load_model
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from keras.optimizers import SGD
import numpy as np
np.random.seed(SEED)
from numpy import vstack
from numpy import hstack
from sklearn.metrics import classification_report, f1_score, confusion_matrix
from sklearn.metrics import roc_curve,roc_auc_score, accuracy_score, precision_score, recall_score



from art.attacks.evasion import FastGradientMethod, CarliniL2Method, ZooAttack, CarliniL2Method, BoundaryAttack, SimBA, HopSkipJump
from art.estimators.classification import KerasClassifier
from art.utils import load_dataset

from scipy.stats import wasserstein_distance
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
import copy

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
from ipywidgets import interact
from datetime import datetime
import os

import tensorflow as tf
tf.compat.v1.disable_eager_execution()

from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr

tf.compat.v1.random.set_random_seed(42)
np.random.seed(42)

import SwarmPackagePy

"""#Mount Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# Read MNIST dataset"""

# Read MNIST dataset
(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str("mnist"))

x_test.shape

"""#Utility functions"""

def show_digit(x, y, pred=None):
  plt.title('True: {label} and Predicted: {pred}'.format(label=np.argmax(y), pred=np.argmax(pred)))
  plt.imshow(x.reshape((28,28)), cmap='Greys_r')

def l_2_dist(orig_img, new_img):
    return np.sqrt(np.sum((orig_img.ravel()-new_img.ravel())**2))

def l_inf_dist(orig_img, new_img):
    return np.max(np.abs(orig_img.ravel() - new_img.ravel()))

def l_0_dist(orig_img, new_img):
    return np.sum((orig_img.ravel() - new_img.ravel()) != 0)

def get_dataset_l_2_dist(orig_img, new_img):
  dist = []
  for i in range(orig_img.shape[0]):
    dist.append(np.sqrt(np.sum((orig_img[i].ravel()-new_img[i].ravel())**2)))
  return np.mean(dist)

def get_all_dist(x_clean, x_adv):
  l_2 = round(l_2_dist(x_clean, x_adv), 4)
  l_inf = round(l_inf_dist(x_clean.ravel(), x_adv.ravel()), 4)
  ws = round(wasserstein_distance(x_clean.ravel(), x_adv.ravel()), 4)
  ssim_d = round(ssim(x_clean.ravel(), x_adv.ravel()), 4)
  psnr_d = round(psnr(x_clean.ravel(), x_adv.ravel()),4)
  dist =  {'L2': l_2, 'L-INF': l_inf,'WS': ws, 'ssim': ssim_d, 'psnr': psnr_d}
  return dist

def get_dist_metrics(dist_params):
  dist_metrics = {}
  for key in dist_params:
    #print('\nDistances for ', key)
    x_clean = dist_params[key][0]
    x_adv = dist_params[key][1]
    try:
      if(x_clean.shape != x_adv.shape):
        raise ValueError("get_dist_metrics:Size of the both datsets not same for: ", key)
    except ValueError as ve:
      print(ve)
      continue
    dist_metrics[key] = {'L2': round(get_dataset_l_2_dist(x_clean, x_adv), 4),
                         'L-INF': round(l_inf_dist(x_clean.ravel(), x_adv.ravel()), 4),
                         'WS': round(wasserstein_distance(x_clean.ravel(), x_adv.ravel()), 4),
                         'ssim': round(ssim(x_clean.ravel(), x_adv.ravel()), 4),
                         'psnr': round(psnr(x_clean.ravel(), x_adv.ravel()),4)
                         }
    #print(dist_metrics[key])
  return dist_metrics

### USAGE
# dist_params = {'FGSM': [x_test_random, x_test_random_fgsm],
#                'ZOO' : [x_test_random, x_test_zoo],
#                'BOUNDARY': [x_test_random, x_test_random_boundary],
#                'CSO' : [x_test_random, x_test_cso]
    
# }

def counter(func):
  def wrapper(*args, **kwargs):
    wrapper.count += 1
    # Call the function being decorated and return the result
    return func(*args, **kwargs)
  wrapper.count = 0
  # Return the new decorated function
  return wrapper

def get_accuracy(y_pred, y_true):  
  acc = np.sum(np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1)) / y_true.shape[0]
  #print("\nTest accuracy : %.2f%%" % (acc * 100))
  return acc * 100

def get_mis_preds(y_true, y_preds):
  return np.where(np.argmax(y_true, axis=1) != np.argmax(y_preds, axis=1))[0]

def get_correct_preds(y_true, y_preds):
  return np.where(np.argmax(y_true, axis=1) == np.argmax(y_preds, axis=1))[0]

def browse_mis_samples(clean_images, adv_images, y_true, y_pred, verbose=True):
  total_images = len(adv_images)
  mis_preds = get_mis_preds(y_true, y_pred)
  

  #print("Before Clean shape: {} adv shape: {}".format
   #     (clean_images.shape, adv_images.shape))


  clean_images = clean_images[mis_preds]
  adv_images = adv_images[mis_preds]

  #print("Afer mispred Clean shape: {} adv shape: {}".format
   #     (clean_images.shape, adv_images.shape))


  #N = clean_images.shape[0]
  N = len(mis_preds)
  if (N == 0):
    print("There are zero mis-classified images!")
    return
  
  print("Mis-classified Images: {} out of Total: {}".format(N, total_images))
  if(verbose):
    print("Mis preds: ", mis_preds)
    print("Mean L2 Dist.: ", get_dataset_l_2_dist(clean_images, adv_images))
  rows = 1
  columns = 2
  def view_image(i=0):
      fig = plt.figure(figsize=(5, 3))
      true_label = np.argmax(y_true[mis_preds[i]])
      pred_label = np.argmax(y_pred[mis_preds[i]])
      fig.add_subplot(rows, columns, 1)
      plt.imshow(clean_images[i].reshape(28,28), cmap='Greys_r', interpolation='nearest')
      plt.axis('off')
      plt.title("#{} Clean Img.True:{}".format(i,true_label))

      fig.add_subplot(rows, columns, 2)
      plt.imshow(adv_images[i].reshape(28,28), cmap='Greys_r', interpolation='nearest')
      plt.axis('off')
      plt.title("Adv Img. Predicted: {} ".format(pred_label))
      dist = "L2 Dist: {}".format(l_2_dist(clean_images[i], adv_images[i]))
      fig.suptitle(dist, y=0.1)
  interact(view_image, i=(0, N-1))

def browse_all_samples(clean_images, adv_images, y_true, y_pred, mis= True):

  N = len(clean_images)
  print("Total  Images: ", N)
  rows = 1
  columns = 2
  def view_image(i=0):
      fig = plt.figure(figsize=(3, 2))
      true_label = np.argmax(y_true[i])
      pred_label = np.argmax(y_pred[i])
      fig.add_subplot(rows, columns, 1)
      plt.imshow(clean_images[i].reshape(28,28), cmap='Greys_r', interpolation='nearest')
      plt.axis('off')
      plt.title("#{} Clean Image. True Label: {}".format(i,true_label))

      fig.add_subplot(rows, columns, 2)
      plt.imshow(adv_images[i].reshape(28,28), cmap='Greys_r', interpolation='nearest')
      plt.axis('off')
      plt.title("Adv Image. Predicted: {} ".format(pred_label))
  interact(view_image, i=(0, N-1))

def get_random_correct_samples(size,x_test, y_true, y_pred, seed = SEED):
  np.random.seed(seed)
  #y_test_label = np.argmax(y_test, axis=1)
  #y_pred_label = np.argmax(y_pred, axis=1)
  #print("y_test_label", y_test_label)

  correct_indices = get_correct_preds(y_true, y_pred)
  rand_indices = np.random.choice(correct_indices, size = size)
  return x_test[rand_indices], y_true[rand_indices], rand_indices

def get_random_any_samples(size,x_train, y_train):
  np.random.seed(SEED)
  #y_test_label = np.argmax(y_test, axis=1)
  #y_pred_label = np.argmax(y_pred, axis=1)
  #print("y_test_label", y_test_label)
  rand_indices = np.random.choice(np.array(y_train.shape[0]), size = size)
  return x_train[rand_indices], y_train[rand_indices], rand_indices

def save_dataset(dataset, basedir):
  dataset_temp = copy.deepcopy(dataset)
  clean_y = dataset_temp.pop('CLEAN_Y')
  filename = basedir + "CLEAN_Y" + ".csv"
  print("Saving CLEAN_Y: ", filename)
  np.savetxt(filename, clean_y, delimiter=',' )
  for key in dataset_temp:
    print("Saving..: ", key)
    filename = basedir + key + ".csv"
    print(filename)
    x = np.reshape(dataset_temp[key], ((dataset_temp[key].shape[0],
                                        dataset_temp[key].shape[1] * dataset_temp[key].shape[2])))
    np.savetxt(filename, x, delimiter=',' )

def load_adv_dataset(params, basedir, x_dim):
  print("Loading dataset from dir: ", basedir)
  dataset = {}
  clean_y = params.pop(0)
  filename = basedir + "CLEAN_Y" + ".csv"
  print("Loading CLEAN_Y: ", filename)
  dataset['CLEAN_Y'] = np.genfromtxt(filename,delimiter=',' )
  for key in params:
    print("Loading..: ", key)
    filename = basedir + key + ".csv"
    print(filename)
    x_temp = np.genfromtxt(filename, delimiter = ',')
    dataset[key] = np.reshape(x_temp, (x_dim))
  return dataset

"""## Evaluation Functions"""

def get_perf_metrics(actual, predictions, verbose = 1):
  accuracy = accuracy_score(np.argmax(actual, axis=1), np.argmax(predictions, 
                                                                 axis=1))
  precision = precision_score(np.argmax(actual, axis=1), np.argmax(predictions, 
                                                                   axis=1), average='micro')
  recall = recall_score(np.argmax(actual, axis=1), np.argmax(predictions, 
                                                                   axis=1), average='micro')
  f1 = f1_score(np.argmax(actual, axis=1), np.argmax(predictions, 
                                                                   axis=1), average='micro')
  
  if (verbose != 0):
    print("Accuracy: %f, Precision: %f, \nRecall: %f, F1 Score: %f\n"%
          (accuracy, precision, recall, f1))
  return {
      "accuracy" : accuracy,
      "precision" : precision,
      "recall" : recall,
      "f1_score" : f1
  }

def evaluate_classifier(classifier, eval_params):
  classifier_evals = {}
  params = copy.deepcopy(eval_params)
  x_test_random = params.pop('CLEAN_X')
  y_test_random = params.pop('CLEAN_Y')

  print("\nEvaluating CLEAN: ")
  predictions = classifier.predict(x_test_random)
  classifier_evals['CLEAN'] = get_perf_metrics(y_test_random, predictions)

  for key in params:
    print("\nEvaluating: ", key)
    test_x = params[key]
    predictions = classifier.predict(test_x)
    classifier_evals[key] = get_perf_metrics(y_test_random, predictions)
  return classifier_evals

## USAGE:
# eval_params = {'ALL_Clean_TEST_SET' : [x_test, y_test],
#                'Random Clean Test' : [x_test_random, y_test_random],
#                'FGSM': [x_test_fgsm, y_test_random],
#                'ZOO' : [x_test_zoo, y_test_random],
#                'BOUNDARY': [x_test_boundary, y_test_random],
#                'CSO' : [x_test_cso, y_test_random]
#                }

### USAGE
# dist_params_soft = {'FGSM': [x_test_random, x_test_soft_fgsm],
#                'ZOO' : [x_test_random, x_test_soft_zoo],
#                'BOUNDARY': [x_test_random, x_test_soft_boundary],
#                'CSO' : [x_test_random, x_test_soft_cso]
    
# }

"""# Attack Function

## Driver Functions
"""

## WIP 
def generate_adv_datsets(model, x_test, y_test, attack_list, 
                         n=10, epsilon=0.001, seed=SEED):
  #np.random.seed(SEED)
  x_adv = {}
  classifier = KerasClassifier(model) #For ART attacks
  
  x_test_random, y_test_random, rand_indices = get_random_correct_samples(
      n, x_test, y_test, model.predict(x_test))
  x_adv['CLEAN_X'] = x_test_random
  x_adv['CLEAN_Y'] = y_test_random

  for attack in attack_list:
    if(attack == 'FGSM'):
      print("\nGenerating adv examples using attack FGSM")
      epsilon = 0.1  # Maximum perturbation
      adv_crafter = FastGradientMethod(classifier, eps=epsilon)
      x_adv[attack] = adv_crafter.generate(x=x_test_random)
    
    if(attack == 'CWL2'):
      print("\nGenerating adv examples using attack CWL2")
      #epsilon = 0.1  # Maximum perturbation
      adv_crafter = CarliniL2Method(classifier)
      x_adv[attack] = adv_crafter.generate(x=x_test_random)

    elif(attack == 'BOUNDARY'):
      print("\nGenerating adv examples using attack BOUNDARY")
      boundary = BoundaryAttack(classifier, targeted=False)
      x_adv[attack] = boundary.generate(x_test_random)

    elif(attack == 'ZOO'):
      print("\nGenerating adv examples using attack ZOO")
      zoo = ZooAttack(
          classifier=classifier,
          confidence=0.0,
          targeted=False,
          learning_rate=1e-2,
          max_iter=200,
          binary_search_steps=10,
          initial_const=1e-3,
          abort_early=True,
          use_resize=False,
          use_importance=False,
          nb_parallel=128,
          batch_size=1,
          variable_h=0.01
      )
      x_adv[attack] = zoo.generate(x_test_random)

    elif(attack == 'SIMBA'):
      print("\nGenerating adv examples using attack SIMBA")
      simba = SimBA(classifier)
      x_adv[attack] = simba.generate(x_test_random)
    
    elif(attack == 'HOPSKIPJUMP'):
      print("\nGenerating adv examples using attack HOPSKIPJUMP")
      hopskipjump = HopSkipJump(classifier)
      x_adv[attack] = hopskipjump.generate(x_test_random)

    elif(attack == 'CSO'):
      print("\nGenerating adv examples using attack CSO")
      #Already tuned hyper-parameters
      loss, l_2_mean, query_mean, x_test_cso = get_cso_adv(model, x_test_random, 
                                                     y_test_random, n=800, pa=.25,
                                                    iterations=1, epsilon=epsilon)
      x_adv[attack] = x_test_cso
  return x_adv

### USAGE:
# %%time
# adv_dataset_soft = generate_adv_datsets(model_soft,x_test, y_test,
#                                         attack_list=['FGSM', 'BOUNDARY', 'ZOO',
#                                                      'SIMBA', 'HOPSKIPJUMP',
#                                                      'CSO'])
# x_test_soft_random = adv_dataset_soft['CLEAN_X']
# y_test_soft_random = adv_dataset_soft['CLEAN_Y']

#save_dataset(adv_dataset_soft,'/content/drive/MyDrive/adv-ml/soft/')



"""## Functions for Adv Example generation using CSO"""

# TAKES ARGUMENTS
def get_cso_adv(model, x_test_random, y_test_random, 
                n=150, iterations = 1, pa=0.5, nest=784, epsilon = 3.55):
  iteration = round(iterations)
  n = round(n)
  print("n: {} Iteration:{} and espilon: {}".format(n,iteration, epsilon))

  no_samples = len(x_test_random)
  adv_cso = np.empty((no_samples,28,28,1))

  i = 0
  query_count = []
  l_2 = []
  for i in range(no_samples):
    #print("Generating example: ", i)
    adv_cso[i], count, dist = get_adv_example(model, x_test_random[i], y_test_random[i] , 
                                        pa=pa, n=n, nest=nest, iterations = iteration, 
                                        epsilon = epsilon) 
    query_count.append(count)
    l_2.append(dist)

  x_test_cso = adv_cso
  y_pred_cso = model.predict(x_test_cso)
  acc = get_accuracy(y_pred_cso, y_test_random)
  #l_2 = get_dataset_l_2_dist(x_test_random, x_test_cso)
  l_2_mean = np.mean(l_2)
  query_mean = np.mean(query_count)
  print("Accuracy: {} Mean L2 Counted: {} Query: {}".format(
      acc, l_2_mean,query_mean, l_2_dist(x_test_random.ravel(), x_test_cso.ravel())))
  
  #PRODUCTION
  if (acc == 0):
    return -l_2_mean, l_2_mean, query_mean, x_test_cso
  return  acc * (-l_2_mean),l_2_mean, query_mean, x_test_cso
  
  # #MAXIMIZE
  # if (acc == 0):
  #   return -l_2_mean 
  # return  acc * (-l_2_mean)
  # # ##MINIMIZE
  # if (acc == 0):
  #   return l_2_mean
  # return  acc * l_2_mean

def process_digit(x_clean, x_prop, epsilon):
  x_clean_ravel = np.copy(x_clean.ravel())
  #for idx in range(len(x_clean_ravel)):
  #print("\nValue at IDX:{} is: {}".format(idx, x_clean_ravel[idx]))
    #print("Proposed Value:", x_prop[idx])
    #if (np.random.uniform() > 0.5):
      #x_clean_ravel[idx] += x_prop[idx]  * epsilon
    #print("New Value:", x_clean_ravel[idx])
  x_clean_ravel += x_prop * epsilon
  #x_clean_ravel = np.uint8(x_clean_ravel)/255.0
  #x_clean_ravel = x_clean_ravel/255.0
  #x_clean_ravel = (x_clean_ravel-min(x_clean_ravel)) / (max(x_clean_ravel)-min(x_clean_ravel))
  return x_clean_ravel.reshape((28,28,1))
  # x_clean_ravel = np.copy(x_clean.ravel())
  # x_clean_ravel +=  x_prop * epsilon
  # x_clean_ravel = np.uint8(x_clean_ravel)/255.0
  # return x_clean_ravel.reshape((28,28,1))

def get_adv_example(model, x_clean, y_clean, n=100, pa=0.5, nest=784, iterations = 10, epsilon = 0.001):
  @counter
  def evaluate_acc(x):
    x_adv = process_digit(x_clean, x, epsilon)
    predictions = model.predict(x_adv.reshape((1,28,28,1)))[0]
    return predictions[np.argmax(y_clean)]
    #return l_2_dist(x_clean, x_adv)
    #return l_2_dist(x_clean, x_adv)
    #return 100
    
  total_indices = len(x_clean.ravel())
  lb = np.empty(total_indices)
  lb.fill(0)
  ub = np.empty(total_indices)
  ub.fill(1)
  alh = SwarmPackagePy.cso(n, evaluate_acc, lb, ub, total_indices, pa=pa, 
                           nest=nest,
                           iteration=iterations)
  x = np.array(alh.get_Gbest())
  x_adv = process_digit(x_clean, x, epsilon)
  dist = l_2_dist(x_clean, x_adv)
  adv_pred = np.argmax(model.predict(x_adv.reshape((1,28,28,1))))
  attack_succ = np.argmax(y_clean) != adv_pred
  print("Attack result:{}, Dist:{}".format(attack_succ, dist))
  return x_adv, evaluate_acc.count, dist

model_logit = load_model("/content/drive/MyDrive/adv-ml/mnist")

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # adv_cso = generate_adv_datsets(model_logit, x_test, y_test, 
# #                               attack_list=['CSO'], n=5, epsilon=.75)

n_samples = 5
x_test_random, y_test_random, rand_ind = get_random_correct_samples(
    n_samples, x_test, y_test, model_logit.predict(x_test), seed = 1231)

loss, l_2_mean, query_mean, x_test_cso = get_cso_adv(model_logit, x_test_random, 
                                                     y_test_random, n=400, pa=.25,
                                                    iterations=2, epsilon=0.4)

browse_mis_samples(x_test_random,
                   x_test_random/2,
                   y_test_random,
                   model_logit.predict(x_test_random/2)
                   )

(x_test_random[0]/0.9)/np.argmax(x_test_random[0])

browse_all_samples(x_test_random,
                   x_test_cso,
                   y_test_random,
                   model_logit.predict(x_test_cso)
                   )

# from scipy.spatial import distance
# distance.euclidean(adv_cso['CLEAN_X'][1].ravel(), adv_cso['CSO'][1].ravel())

# from skimage import util
# c = util.compare_images(adv_cso['CSO'][1], adv_cso['CLEAN_X'][1])
# show_digit(c, 1)



"""## FB NeverGrad"""

! pip install nevergrad

import nevergrad as ng

model_logit = load_model('/content/drive/MyDrive/adv-ml/mnist')

"""### Using DE"""

def process_digit(x_clean, x_prop, epsilon):
  #print("X PROP Size: ", x_prop.size)
  x_clean_ravel = np.copy(x_clean.ravel())
  x_clean_ravel += x_prop * epsilon
  x_clean_ravel = (x_clean_ravel-min(x_clean_ravel)) / (max(x_clean_ravel)-min(x_clean_ravel))
  return x_clean_ravel.reshape((28,28,1))
  
def get_adv_nvg_example(model,optimizer, x_clean, y_clean, 
                        epsilon = 0.5):
  @counter
  def evaluate_acc(x):
    x_adv = process_digit(x_clean, x, epsilon)
    predictions = model.predict(x_adv.reshape((1,28,28,1)))[0]
    return np.log(predictions[np.argmax(y_clean)]) # * l_2_dist(x_clean, x_adv))
    #return np.log(predictions[np.argmax(y_clean)]) #* l_2_dist(x_clean, x_adv))
  
  xopt = optimizer.minimize(evaluate_acc)
  x = np.array(xopt.value)
  x_adv = process_digit(x_clean, x, epsilon)
  dist = l_2_dist(x_clean, x_adv)
  adv_pred = np.argmax(model.predict(x_adv.reshape((1,28,28,1))))
  attack_succ = np.argmax(y_clean) != adv_pred
  print("Attack result:{}, Queries: {} Dist:{}".format(attack_succ,
                                                       evaluate_acc.count, dist))
  return x_adv, evaluate_acc.count, dist

def get_nvg_adv(model, x_test_random, y_test_random, 
                iterations = 100, epsilon = 3.55, max_l_2=6):
  iteration = round(iterations)
  print("Iterations:{}, espilon: {} and Max-L2:{}".format(
      iteration, epsilon, max_l_2))

  no_samples = len(x_test_random)
  adv_nvg = np.empty((no_samples,28,28,1))

  i = 0
  query_count = []
  l_2 = []
  params = ng.p.Array(shape=(784,)).set_bounds(0, 1)
  for i in range(no_samples):
    print("Generating example: ", i)
    params = ng.p.Array(shape=(784,)).set_bounds(0, 1)
    #params.value = np.zeros_like(x_test_random[i].ravel())
    
    optimizer = ng.optimizers.AlmostRotationInvariantDE(budget=iterations, 
                                 parametrization=params)
    # DEthenPSO = ng.optimizers.Chaining([
    #                                      ng.optimizers.AlmostRotationInvariantDE,
    #                                      ng.optimizers.RealSpacePSO], [iterations]
    #                                     )
    # optimizer = DEthenPSO(budget=iterations, parametrization=params)
    
    optimizer.parametrization.register_cheap_constraint(
       lambda x: l_2_dist(
           process_digit(x_test_random[i], x, epsilon), x_test_random[i]) < max_l_2)
    
    adv_nvg[i], count, dist = get_adv_nvg_example(model, optimizer,
                                                  x_test_random[i],
                                                  y_test_random[i] , 
                                                  epsilon = epsilon
                                                  )
    query_count.append(count)
    l_2.append(dist)

  x_test_nvg = adv_nvg
  y_pred_nvg = model.predict(x_test_nvg)
  acc = get_accuracy(y_pred_nvg, y_test_random)
  #l_2 = get_dataset_l_2_dist(x_test_random, x_test_nvg)
  l_2_mean = np.mean(l_2)
  query_mean = np.mean(query_count)
  print("Accuracy: {} Mean L2 Counted: {} Query: {}".format(
      acc, l_2_mean,query_mean, l_2_dist(x_test_random.ravel(), x_test_nvg.ravel())))
  
  #PRODUCTION
  if (acc == 0):
    return -l_2_mean, l_2_mean, query_mean, x_test_nvg
  return  acc * (-l_2_mean),l_2_mean, query_mean, x_test_nvg
  
  # #MAXIMIZE
  # if (acc == 0):
  #   return -l_2_mean 
  # return  acc * (-l_2_mean)
  # # ##MINIMIZE
  # if (acc == 0):
  #   return np.log(l_2_mean)
  # return  np.log(acc * l_2_mean)

n_samples = 20
x_test_random, y_test_random, rand_ind = get_random_correct_samples(
    n_samples, x_test, y_test, model_logit.predict(x_test), seed=1234)

"""###DE"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# loss, l_2_mean, query_mean, x_test_nvg = get_nvg_adv(model_logit, x_test_random, 
#                                                      y_test_random,
#                                                     iterations=10000, epsilon=.4,
#                                                      max_l_2=4)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# loss, l_2_mean, query_mean, x_test_nvg = get_nvg_adv(model_logit, x_test_random, 
#                                                      y_test_random,
#                                                     iterations=2000, epsilon=.35)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# loss, l_2_mean, query_mean, x_test_nvg = get_nvg_adv(model_logit, x_test_random, 
#                                                      y_test_random,
#                                                     iterations=1000, epsilon=.45)

browse_mis_samples(x_test_random,
                   x_test_nvg,
                   y_test_random,
                   model_logit.predict(x_test_nvg))

browse_all_samples(x_test_random,
                   x_test_nvg,
                   y_test_random,
                   model_logit.predict(x_test_nvg))

"""### BO DE"""

iters = ng.p.Scalar().set_bounds(0,3000).set_integer_casting()
eps = ng.p.Scalar().set_bounds(0,1)
l_2 = ng.p.Scalar().set_bounds(0,5)
ng.p.Scalar()
instru = ng.p.Instrumentation(model_logit, 
                              x_test_random, 
                              y_test_random,
                              iterations=iters, 
                              epsilon=eps,
                              max_l_2=l_2)
bo = ng.optimizers.BO(parametrization=instru, budget=2)

recommendation = bo.minimize(get_nvg_adv)
print(recommendation.value)

from bayes_opt import BayesianOptimization

def get_nvg_adv_optimize(iterations=500, epsilon = 0.5,max_l_2=5):
  return get_nvg_adv(model_logit,
                     x_test_random, 
                     y_test_random,
                     iterations=round(iterations), 
                     epsilon=epsilon,
                     max_l_2=max_l_2
                     )

# Bounded region of parameter space
pbounds = {
    'iterations': (500, 2000), 'epsilon': (0.1, 1), 'max_l_2' : (3, 6)}

optimizer = BayesianOptimization(
    f=get_nvg_adv_optimize,
    pbounds=pbounds,
    random_state=1
)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# optimizer.maximize(init_points=2,
#     n_iter=3,
#     random_state=1
# )

optimizer.max

# Commented out IPython magic to ensure Python compatibility.
# %%time
# loss, l_2_mean, query_mean, x_test_nvg = get_nvg_adv(model_logit, 
#                                                      x_test_random, 
#                                                      y_test_random,
#                                                      iterations=1580, 
#                                                      epsilon=0.47531980423231657,
#                                                      max_l_2=5
#                                                      )

browse_mis_samples(x_test_random,
                   x_test_nvg,
                   y_test_random,
                   model_logit.predict(x_test_nvg))

browse_all_samples(x_test_random,
                   x_test_nvg,
                   y_test_random,
                   model_logit.predict(x_test_nvg))

"""## Use Optymizer Library"""

! python3 --version

model_logit = load_model('/content/drive/MyDrive/adv-ml/mnist')

from opytimark.markers.n_dimensional import Sphere
import opytimizer
from opytimizer import Opytimizer
from opytimizer.core import Function
from opytimizer.functions import ConstrainedFunction
from opytimizer.optimizers.swarm import CS
from opytimizer.optimizers.evolutionary import GA, HS, FOA, GP, DE, IWO, EP, ES, CRO
from opytimizer.optimizers.misc.aoa import AOA
from opytimizer.optimizers.misc.hc import HC
from opytimizer.optimizers.misc.cem import CEM
from opytimizer.spaces import SearchSpace, TreeSpace

np.random.seed(SEED)

import logging

# Gathers all instantiated loggers, even the children
loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]

# Iterates through all loggers and set their level to INFO
for logger in loggers:
    logger.setLevel(logging.INFO)

def process_digit(x_clean, x_prop, epsilon):
  # print("X PROP Shape: ", x_prop.shape)
  # print("x_clean Shape in process_digit: ", x_clean.shape)
  x_clean_temp = np.copy(x_clean.ravel())
  x_clean_temp += x_prop.ravel() * epsilon
  x_clean_temp = (x_clean_temp-min(x_clean_temp)) / (max(x_clean_temp)-min(x_clean_temp))
  return x_clean_temp.reshape((28,28,1))
  
def get_adv_opyt_example(model,optimizer, x_clean, y_clean,
                        epsilon = 0.5, iterations=100, max_l_2=6, agents=20):
  eval_count = 0

  def evaluate_acc(x):
    nonlocal eval_count
    eval_count += 1
    x_adv = process_digit(x_clean, x, epsilon)
    predictions = model.predict(x_adv.reshape((1,28,28,1)))[0]
    result = predictions[np.argmax(y_clean)]
    #print("Returning: ", result)
    return float(np.log(result)) # * l_2_dist(x_clean, x_adv))
    #return np.log(predictions[np.argmax(y_clean)]) #* l_2_dist(x_clean, x_adv))
  
  def l_2_constraint(x):
    return l_2_dist(x_clean, x) < max_l_2

  @counter
  def unequality_contraint(x):
    x_adv = process_digit(x_clean, x, epsilon)
    predictions = model.predict(x_adv.reshape((1,28,28,1)))[0]
    result = predictions[np.argmax(y_clean)]
    return np.argmax(result) != np.argmax(y_clean)

  # Number of agents and decision variables
  n_agents = agents
  n_variables = 784
  # Lower and upper bounds (has to be the same size as `n_variables`)
  lower_bound = np.empty(n_variables)
  lower_bound.fill(0.2)
  upper_bound = np.empty(n_variables)
  upper_bound.fill(0.99)

  space = SearchSpace(n_agents, n_variables, lower_bound, upper_bound)
  #function = Function(evaluate_acc)
  function = ConstrainedFunction(evaluate_acc, [l_2_constraint], 10000.0)

  # Bundles every piece into Opytimizer class
  opt = Opytimizer(space, optimizer, function, save_agents=False)
  #Runs the optimization task
  opt.start(n_iterations = iterations)

  xopt = opt.space.best_agent.position  
  #x = np.array(xopt.value)
  x_adv = process_digit(x_clean, xopt, epsilon)
  dist = l_2_dist(x_clean, x_adv)
  adv_pred = np.argmax(model.predict(x_adv.reshape((1,28,28,1))))
  attack_succ = np.argmax(y_clean) != adv_pred
  print("Attack result:{}, Queries: {} Dist:{}".format(attack_succ,
                                                       eval_count, dist))
  return x_adv, eval_count, dist

def get_opyt_adv(model, x_test_random, y_test_random, 
                iterations = 100, epsilon = 3.55, max_l_2=6, agents=20):
  iteration = round(iterations)
  print("Iterations:{}, espilon: {} and Max-L2:{}".format(
      iteration, epsilon, max_l_2))

  no_samples = len(x_test_random)
  adv_nvg = np.empty((no_samples,28,28,1))

  i = 0
  query_count = []
  l_2 = []
  for i in range(no_samples):
    print("Generating example: ", i)
    # Creates the optimizer
    optimizer = opytimizer.optimizers.misc.AOA()
    adv_nvg[i], count, dist = get_adv_opyt_example(model, optimizer,
                                                  x_test_random[i],
                                                  y_test_random[i],
                                                  epsilon = epsilon,
                                                  iterations = iterations,
                                                   max_l_2 = max_l_2,
                                                   agents = agents
                                                  )
    query_count.append(count)
    l_2.append(dist)

  x_test_nvg = adv_nvg
  y_pred_nvg = model.predict(x_test_nvg)
  acc = get_accuracy(y_pred_nvg, y_test_random)
  #l_2 = get_dataset_l_2_dist(x_test_random, x_test_nvg)
  l_2_mean = np.mean(l_2)
  query_mean = np.mean(query_count)
  print("\nTotal Examples: {}, Iterations:{}, espilon: {} and Max-L2:{} Agents: {}\nAccuracy: {} Mean L2 Counted: {} Query: {}".format(
      len(y_test_random), iterations, epsilon, max_l_2,agents, acc, l_2_mean,query_mean, 
      l_2_dist(x_test_random.ravel(), x_test_nvg.ravel())))
  
  ##PRODUCTION
  # if (acc == 0):
  #   return -l_2_mean, l_2_mean, query_mean, x_test_nvg
  # return  acc * (-l_2_mean),l_2_mean, query_mean, x_test_nvg
  return  acc,l_2_mean, query_mean, x_test_nvg
  
  # # #MAXIMIZE
  # if (acc == 0):
  #   return -l_2_mean 
  # return  acc * (-l_2_mean)
  # # ##MINIMIZE
  # if (acc == 0):
  #   return np.log(l_2_mean)
  # return  np.log(acc * l_2_mean)

n_samples = 10
x_test_random, y_test_random, rand_ind = get_random_correct_samples(
    n_samples, x_test, y_test, model_logit.predict(x_test), seed = 1231)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# loss, l_2_mean, query_mean, x_test_opyt = get_opyt_adv(model_logit, 
#                                                      x_test_random, 
#                                                      y_test_random,
#                                                      iterations=200, 
#                                                      epsilon=0.2,
#                                                      max_l_2=3,
#                                                      agents = 20
#                                                      )

print( loss, l_2_mean, query_mean)

#np.savetxt("/content/drive/MyDrive/adv-ml/x_test_opyt_500iters.csv",
 #           x_test_opyt.reshape((100,784)), delimiter=',')



browse_mis_samples(x_test_random,
                   x_test_opyt,
                   y_test_random,
                   model_logit.predict(x_test_opyt))

import skimage

diff = x_test_random[1] - x_test_opyt[1]

show_digit(diff,1, model_logit.predict(x_test_opyt[2].reshape((1,28,28,1))))

browse_all_samples(x_test_random,
                   x_test_opyt,
                   y_test_random,
                   model_logit.predict(x_test_opyt))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# n_samples = 10
# x_test_random, y_test_random, rand_ind = get_random_correct_samples(
#     n_samples, x_test, y_test, model_logit.predict(x_test))
# 
# result = []
# for eps in [0.2, 0.3]:
#   %%timeit 
#   acc, l_2_mean, query_mean, x_test_opyt = get_opyt_adv(model_logit, 
#                                                      x_test_random, 
#                                                      y_test_random,
#                                                      iterations=200, 
#                                                      epsilon=eps,
#                                                      max_l_2=3,
#                                                      agents = 25
#                                                      )
#   result.append({'eps' : eps, 'acc': acc, 'query_mean': query_mean, 
#                  'x_test_opyt' : x_test_opyt})

"""### BO"""

n_samples = 1
x_test_random, y_test_random, rand_ind = get_random_correct_samples(
    n_samples, x_test, y_test, model_logit.predict(x_test))

def get_opyt_adv_optimize(iterations=10, epsilon=0.3):
  acc, l_2_mean, query_mean, x_test_opyt = get_opyt_adv(model_logit, 
                                                     x_test_random, 
                                                     y_test_random,
                                                     iterations=round(iterations), 
                                                     epsilon=epsilon,
                                                     max_l_2=3,
                                                     agents = 25
                                                     )
  if (acc == 0):   
    return -l_2_mean
  else:
    return acc * (-l_2_mean)

# Bounded region of parameter space
pbounds = {'iterations': (10, 200), 'epsilon': (0.1, 0.4)}

optimizer = BayesianOptimization(
    f=get_opyt_adv_optimize,
    pbounds=pbounds,
    random_state=42
)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# optimizer.maximize(init_points=2,
#     n_iter=1,
#     random_state=1
# )

acc, l_2_mean, query_mean, x_test_opyt = get_opyt_adv(model_logit, 
                                                     x_test_random, 
                                                     y_test_random,
                                                     iterations=100, 
                                                     epsilon=eps,
                                                     max_l_2=3,
                                                     agents = 25
                                                     )



"""## Functions for Adv Example Generation using Gaussian Noise"""

def get_random_adv_example(x_clean):
  #x_noise = np.random.normal(np.mean(x_clean.reshape((1,784))), 
   #                                   np.cov((x_clean.reshape((1,784)))), size = 784)
  #x_adv = x_clean + x_noise.reshape((28,28,1)) 
  x_adv = x_clean + np.random.normal()*1.1
  return x_adv, l_2_dist(x_clean, x_adv)

# TAKES ARGUMENTS
def get_random_adv_dataset(model, x_test_random, y_test_random):
  no_samples = len(x_test_random)
  adv_random = np.empty((no_samples,28,28,1))

  i = 0
  l_2 = []
  for i in range(no_samples):
    print("Generating example: ", i)
    adv_random[i], dist = get_random_adv_example(x_test_random[i]) 
    l_2.append(dist)

  y_pred_random = model.predict(adv_random)
  acc = get_accuracy(y_pred_random, y_test_random)
  #l_2 = get_dataset_l_2_dist(x_test_random, x_test_cso)
  l_2_mean = np.mean(l_2)
  print("Accuracy: {} Mean L2: {}".format(acc, l_2_mean))
  
  #PRODUCTION
  return  acc,l_2_mean, x_test_random

# Commented out IPython magic to ensure Python compatibility.
# # ### USAGE
# %%time
# i = 0
# xopt, dist = get_random_adv_example(x_test[i])
# print("L2:", dist)
# # print("WS:", wasserstein_distance(xopt.ravel(), x_test[i].ravel()))
# # print("SSIM:", ssim(xopt.ravel(), x_test[i].ravel()))
# # print("PSNR: ", psnr(xopt.ravel(), x_test[i].ravel()))
# show_digit(xopt,y_test[i], model.predict(xopt.reshape((1,28,28,1))))

"""# Buil CNN Function"""

def create_model(p_activation="linear"):
  model = Sequential()

  model.add(Conv2D(32, (3, 3),activation="relu", input_shape=(28, 28, 1)))

  model.add(Conv2D(32, (3, 3), activation="relu"))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(64, (3, 3), activation="relu"))
  model.add(Conv2D(64, (3, 3), activation="relu"))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Flatten())
  model.add(Dense(200, activation="relu"))
  model.add(Dense(200, activation="relu"))
  model.add(Dense(10, activation=p_activation))

  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
  model.compile(loss = 
                tf.keras.losses.CategoricalCrossentropy(from_logits=True),
                optimizer=sgd, metrics=["accuracy"])
  return model

"""# Train CNN"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = create_model()
# classifier = KerasClassifier(model=model)
# classifier.fit(x_train, y_train, nb_epochs=50, batch_size=128)

#model.save('/content/drive/MyDrive/adv-ml/mnist')

"""# Load Pretrained CNN"""

model = load_model('/content/drive/MyDrive/adv-ml/mnist')
classifier = KerasClassifier(model)

model_soft = load_model('/content/drive/MyDrive/adv-ml/model-soft')
classifier_soft = KerasClassifier(model_soft)

"""# Evaluate the classifier on the benign test set"""

# Using Linear Logit Model
get_accuracy(model.predict(x_test), y_test)

# Using Softmax Model
get_accuracy(model_soft.predict(x_test), y_test)

"""# Expt CSO Min L2!

## Try with Logi Model
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_cso = generate_adv_datsets(model,x_test, y_test,
#                                         attack_list=['CSO'])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_cso = generate_adv_datsets(model,x_test, y_test,
#                                         attack_list=['CSO'])

"""# Load Adv Examples

## Load Logit model dataset
"""

load_params = ['CLEAN_Y', 'CLEAN_X','FGSM', 'BOUNDARY', 'ZOO','SIMBA', 'HOPSKIPJUMP', 'CSO']
basedir = '/content/drive/MyDrive/adv-ml/'
x_dim = (10,28,28,1)

adv_dataset = load_adv_dataset(load_params, basedir, x_dim)

"""## Load Soft Model dataset"""

load_params = ['CLEAN_Y', 'CLEAN_X','FGSM', 'BOUNDARY', 'ZOO','SIMBA', 'HOPSKIPJUMP', 'CSO']
basedir_soft = '/content/drive/MyDrive/adv-ml/soft/'
x_dim = (10,28,28,1)

adv_dataset_soft = load_adv_dataset(load_params, basedir_soft, x_dim)

evaluate_classifier(model, adv_dataset)

evaluate_classifier(model_soft, adv_dataset_soft)

"""# Create Adv Training Dataset"""

y_pred_train = model.predict(x_train)

x_adv_train, y_adv_train, rand_ind_adv = get_random_correct_samples(10, 
                                                                    x_train,
                                                                    y_train, 
                                                                    y_pred_train)

### USAGE:
# %%time
# adv_dataset_soft = generate_adv_datsets(model_soft,x_test, y_test,
#                                         attack_list=['FGSM', 'BOUNDARY', 'ZOO',
#                                                      'SIMBA', 'HOPSKIPJUMP'
#                                                      'CSO'])
# x_test_soft_random = adv_dataset_soft['CLEAN_X']
# y_test_soft_random = adv_dataset_soft['CLEAN_Y']

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_training = generate_adv_datsets(model,x_adv_train, y_adv_train,
#                                         attack_list=['FGSM', 'BOUNDARY', 'ZOO',
#                                                      'SIMBA', 'HOPSKIPJUMP',
#                                                      'CSO'])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_training_tmp = generate_adv_datsets(model,x_adv_train, y_adv_train,
#                                         attack_list=['HOPSKIPJUMP','CSO'])

adv_dataset_training['HOPSKIPJUMP'] = adv_dataset_training_tmp['HOPSKIPJUMP']
adv_dataset_training['CSO'] = adv_dataset_training_tmp['CSO']

evaluate_classifier(model, adv_dataset_training)

#Augment Adv Training Dataset
x_train_aug, y_train_aug = vstack((x_train, adv_dataset_training['CSO'])), vstack((y_train, adv_dataset_training['CLEAN_Y']))

model_adv = create_model()
classifier_adv = KerasClassifier(model_adv)

classifier_adv.fit(x_train_aug, y_train_aug, nb_epochs=50, batch_size=128)

eu = evaluate_classifier(model, adv_dataset)

e = evaluate_classifier(classifier_adv, adv_dataset)

y_pred_adv = model_adv.predict(x_test)

get_accuracy(y_pred_adv, y_test)

x_test_random_adv, y_test_random_adv, rand_ind_adv = get_random_correct_samples(10, x_test, 
                                                                 y_test, y_pred_adv)

get_accuracy(model_adv.predict(x_test_random_adv), y_test_random_adv)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_test_adv = generate_adv_datsets(model_adv,
#                                         x_test_random_adv, 
#                                         y_test_random_adv,
#                                         attack_list=['FGSM', 'BOUNDARY', 'ZOO',
#                                                      'SIMBA', 'HOPSKIPJUMP',
#                                                      'CSO'])

ed = evaluate_classifier(model_adv, adv_dataset_test_adv)

#model_adv.save("/content/drive/MyDrive/adv-ml/adv-training/model-adv")

#save_dataset(adv_dataset_test_adv, "/content/drive/MyDrive/adv-ml/adv-training/attack/")

#save_dataset(adv_dataset_training, "/content/drive/MyDrive/adv-ml/adv-training/training/")

x_train_random_adv, y_train_random_adv, rand_ind_train_adv = get_random_correct_samples(1000, 
                                                                  x_train, 
                                                                  y_train,
                                                                  model_adv.predict(x_train))

get_accuracy(model_adv.predict(x_train_random_adv), y_train_random_adv)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_train_cso = generate_adv_datsets(model_adv, 
#                                      x_train, 
#                                      y_train,
#                                      attack_list=['CSO'],
#                                      n=1000)

adv_train_cso['CSO'].shape

get_accuracy(model_adv.predict(adv_train_cso['CSO']), adv_train_cso['CLEAN_Y'])

evaluate_classifier(model, adv_train_cso)

browse_mis_samples(adv_train_cso['CLEAN_X'], 
                   adv_train_cso['CSO'], 
                   adv_train_cso['CLEAN_Y'], 
                   model_adv.predict(adv_train_cso['CSO'])
                   )

save_dataset(adv_train_cso, '/content/drive/MyDrive/adv-ml/adv-training/training')

#Augment Adv Training Dataset
x_train_aug, y_train_aug = vstack((x_train, adv_train_cso['CSO'])), vstack((y_train, adv_train_cso['CLEAN_Y']))

adv_train_cso['CSO'][0].shape

adv_train_cso['CLEAN_Y'][:10].shape

show_digit(adv_train_cso['CSO'][0],adv_train_cso['CLEAN_Y'][0],
           model_adv.predict(adv_train_cso['CSO'][0].reshape((1,28,28,1))))

model_adv = create_model()
classifier_adv = KerasClassifier(model_adv)

classifier_adv.fit(x_train_aug, y_train_aug, nb_epochs=50, batch_size=128)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_test_adv = generate_adv_datsets(
#     model_adv, x_test, y_test, 
#     attack_list=['FGSM', 'CWL2', 
#                  'BOUNDARY', 'ZOO', 
#                  'SIMBA', 'HOPSKIPJUMP','CSO'],
#     n=10
# )

q= evaluate_classifier(model_adv, adv_dataset_test_adv)

#Augment Adv Training Dataset
x_train_aug_100, y_train_aug_100 = vstack((x_train, adv_train_cso['CSO'][0:100])), vstack((y_train, adv_train_cso['CLEAN_Y'][0:100]))

adv_train_cso['CSO'].shape

model_adv_100 = create_model()
classifier_adv_100 = KerasClassifier(model_adv_100)

classifier_adv_100.fit(x_train_aug_100, y_train_aug_100, nb_epochs=50, batch_size=128)

q= evaluate_classifier(model_adv_100, adv_dataset_test_adv)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset_test_adv = generate_adv_datsets(
#     model_adv_100, x_test, y_test, 
#     attack_list=['FGSM', 'CWL2', 
#                  'BOUNDARY', 'ZOO', 
#                  'SIMBA', 'HOPSKIPJUMP','CSO'],
#     n=10
# )

"""#adv_train_evaluate"""

def adv_train_evaluate(x_train, y_train, x_test, y_test,  
                       model_type="logit", 
                       attack_list = ['FGSM', 'CWL2', 'BOUNDARY', 'ZOO', 
                                      'SIMBA', 'HOPSKIPJUMP','CSO'],
                       train_on = 'CSO', 
                       n_attack = 10, n_training = 100,epochs=20,
                       epsilon=1.25):
  model = None
  if(model_type == "logit"):
    model = create_model(p_activation="linear")
  elif(model_type == 'softmax'):
    model = create_model(p_activation="softmax")
  print("Training on benign training data")
  model.fit(x_train, y_train, epochs=epochs , batch_size=128)
  
  print("Performance of Model on benign test data")
  eval_params = {"CLEAN_X": x_test, 'CLEAN_Y': y_test}
  e1 = evaluate_classifier(model,eval_params)

  ##########
  print("\n########## Attack:On Benign Trained Model")
  adv_dataset = generate_adv_datsets(model, 
                                     x_test, 
                                     y_test, 
                                     attack_list=attack_list,
                                     n=n_attack,
                                     epsilon = epsilon
                                     )
  print("\tPerformance:")
  e2 = evaluate_classifier(model, adv_dataset)

  ##########
  print("\n########## Adv Training")
  print("\tGenerate Adv Training Dataset, n={} using {}".format(n_training, train_on))
  adv_training_dataset_100 = generate_adv_datsets(model, 
                                     x_train, 
                                     y_train, 
                                     attack_list=[train_on],
                                     n=n_training,
                                     epsilon=epsilon
                                     )
  print("\tAugment Adv {} Examples".format(train_on))
  #Augment Adv Training Dataset
  x_train_aug_100, y_train_aug_100 = vstack((x_train, adv_training_dataset_100[train_on])), vstack((y_train, adv_training_dataset_100['CLEAN_Y']))
  print("\tTrain using Aug Adv {} Examples".format(train_on))
  model_adv_100 = create_model()
  model_adv_100.fit(x_train_aug_100, y_train_aug_100, epochs=epochs , 
                         batch_size=128)
  print("\tPerformance on Benign Test data:")
  eval_params = {"CLEAN_X": x_test, 'CLEAN_Y': y_test}
  e3 = evaluate_classifier(model_adv_100, eval_params)

  ##########
  print("\n########## Attack:On Adv Trained Model")
  print("\tGenerate Adv Attack Examples against Adv Trained model")
  adv_dataset_test_adv = generate_adv_datsets(model_adv_100, 
                                     x_test, 
                                     y_test, 
                                     attack_list=attack_list,
                                     n=n_attack,
                                     epsilon=epsilon
                                     )
  print("\tPerformance on Adv Examples:")
  e4 = evaluate_classifier(model_adv_100, adv_dataset_test_adv)
  return model, model_adv_100, adv_dataset, adv_training_dataset_100, adv_dataset_test_adv

"""##Expt#1"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset, adv_training_dataset_400, adv_dataset_test_adv = adv_train_evaluate(x_train, y_train, x_test, y_test, n_attack=2,
#                                  n_training=2)

"""##Expt#2"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# adv_dataset, adv_training_dataset_400, adv_dataset_test_adv = adv_train_evaluate(x_train, y_train, x_test, y_test, n_attack=2,
#                                  n_training=2)

"""##Expt#3"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model, model_adv_400, adv_dataset, adv_training_dataset_400, adv_dataset_test_adv = adv_train_evaluate(
#     x_train, y_train, x_test, y_test, n_attack=10, n_training=400, model_type = "softmax", 
#     epochs = 50)

#adv_dataset, adv_training_dataset_2, adv_dataset_test_adv
get_all_dist(adv_dataset_test_adv['CLEAN_X'], adv_dataset_test_adv['BOUNDARY'])

get_all_dist(adv_dataset_test_adv['CLEAN_X'], adv_dataset_test_adv['CSO'])

img1 = adv_dataset_test_adv['CSO'][0]
show_digit(img1, 1, model_adv_400.predict(img1.reshape((1,28,28,1))))

img2 = adv_dataset_test_adv['CLEAN_X'][0]
show_digit(img2, 1,model.predict(img2.reshape((1,28,28,1))))

browse_mis_samples(adv_dataset_test_adv['CLEAN_X'], 
                   adv_dataset_test_adv['ZOO'],
                   adv_dataset_test_adv['CLEAN_Y'],
                   model_adv_400.predict(adv_dataset_test_adv['ZOO']),
                   )

browse_mis_samples(adv_dataset_test_adv['CLEAN_X'], 
                   adv_dataset_test_adv['BOUNDARY'],
                   adv_dataset_test_adv['CLEAN_Y'],
                   model_adv_400.predict(adv_dataset_test_adv['BOUNDARY']),
                   )

browse_mis_samples(adv_dataset['CLEAN_X'], 
                   adv_dataset['CSO'],
                   adv_dataset['CLEAN_Y'],
                   model.predict(adv_dataset_test_adv['CSO']),
                   )

get_all_dist(adv_dataset['CLEAN_X'][0], adv_dataset['BOUNDARY'][0])

"""##Expt#4 : CWL2 Training"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model, model_adv_400, adv_dataset, adv_training_dataset_400, adv_dataset_test_adv = adv_train_evaluate(
#     x_train, y_train, x_test, y_test,  
#     model_type="logit", 
#     attack_list = ['FGSM', 'CWL2', 'BOUNDARY', 'SIMBA', 'HOPSKIPJUMP','CSO'],
#     train_on = 'CWL2', 
#     n_attack = 10, n_training = 400,epochs=20
# )

browse_all_samples(adv_dataset_test_adv['CLEAN_X'], 
                   adv_dataset_test_adv['CSO'], 
                   adv_dataset_test_adv['CLEAN_Y'], 
                   model_adv_400.predict(adv_dataset_test_adv['CSO']))